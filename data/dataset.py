import os
import logging
import sys
import json
import random
import pickle
import numpy as np
import pandas as pd
from PIL import Image, ImageFile
from einops import rearrange, reduce, repeat
import math
import traceback

from dataclasses import dataclass
from multiprocessing import Value

# import braceexpand

import torch
import torchvision.datasets as datasets
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, IterableDataset, get_worker_info
from torch.utils.data.distributed import DistributedSampler
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm
from pathlib import Path

import os
import json
import math
import random
import numpy as np
import torch
import nibabel as nib

from data.data_loader_cvpr2025challenge import NAME2LOADER


def contains(text, key):
    if isinstance(key, str):
        return key in text
    elif isinstance(key, list):
        for k in key:
            if k in text:
                return True
        return False


class Uni_Mod_Dataset(Dataset):
    def __init__(self, 
                 umls_def_file, 
                 umls_kg_file, 
                 website_knowledge_file, 
                 supplementary_file,
                 sample_umls_def_ratio=0.1, 
                 sample_umls_kg_ratio=0.1, 
                 sample_website_knowledge_def_ratio=1.0,
                 sample_website_knowledge_kg_ratio=1.0,
                 sample_supplementary_def_ratio=1.0,
                 sample_supplementary_kg_ratio=1.0,
                 hard_negative_prob=0.0
                 ):
        """
        This is the dataset of textual knowledge (definition and knowledge-graph)

        Args:
            umls_def_file (csv): umls concepts and definitions
            umls_kg_file (csv): umls knowledge-graph
            website_knowledge_file (json): knowledge collected from internet, definitions and relationships
            supplementary_file (json): supplementary knowledge data generated by LLM
            sample_xxx_ratio (float, optional): sampling ratio of xxx dataset. Defaults to 0.1.
        """
        self.hard_negative_prob = hard_negative_prob
        
        #.tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')
        
        # Load definition and relationships from UMLS
        umls_def_info = pd.read_csv(umls_def_file)   # A2_KEBERT/data/MRDEF_name.csv
        umls_def_info.drop_duplicates(inplace=True)
        # umls_def_cui_list = umls_def_info.iloc[:,0].tolist()
        umls_def_name_list = umls_def_info.iloc[:,1].tolist()
        umls_def_def_list = umls_def_info.iloc[:,2].tolist()
        umls_def_data = [[name.lower(), defi] for name, defi in zip(umls_def_name_list, umls_def_def_list) if isinstance(name, str)]
        umls_def_data_len = len(umls_def_info)  # label - relation - label
        num_umls_def_pool = round(sample_umls_def_ratio * umls_def_data_len)

        umls_kg_info = pd.read_csv(umls_kg_file)   # A2_KEBERT/data/umls_kg.csv
        umls_kg_info.drop_duplicates(inplace=True)
        umls_kg_source_list = umls_kg_info.iloc[:,0].tolist()
        umls_kg_target_list = umls_kg_info.iloc[:,1].tolist()
        umls_kg_edge_list = umls_kg_info.iloc[:,2].tolist()
        umls_kg_data = [[s.lower(), e, t.lower()] for s, e, t in zip(umls_kg_source_list, umls_kg_edge_list, umls_kg_target_list)]
        umls_kg_data_len = len(umls_kg_info) # label - def
        num_umls_kg_pool = round(sample_umls_kg_ratio * umls_kg_data_len)
        
        """
        umls_cui_info = pd.read_csv(umls_cui_file)   # A2_KEBERT/data/umls_cui.csv
        self.umls_cui_source_list = umls_cui_info.iloc[:,0].tolist()
        self.umls_cui_target_list = umls_cui_info.iloc[:,1].tolist()
        """
        
        # Load definition and relationships form website
        with open(website_knowledge_file, 'r') as json_file:
            website_knowledge_dict = json.load(json_file)
            """
            "Ulnar canal": {
                ... ...
                "cleaned_definition": " This anatomical space at the wrist, situated between the flexor retinaculum and the palmar carpal ligament (stretching from the pisiform bone to the hamate bone), serves as a conduit for the ulnar artery and the ulnar nerve as they pass into the hand. ",
                "relations": [
                    [
                        "located between",
                        "flexor retinaculum"
                    ],
                    ... ...
                ]
            }
            """
        website_knowledge_def_data = [[k.lower(), definition] for k,v in website_knowledge_dict.items() for definition in v['cleaned_definition']] # lab, def
        website_knowledge_def_data_len = len(website_knowledge_def_data)  # num of different definitions
        num_website_knowledge_def_pool = round(sample_website_knowledge_def_ratio * website_knowledge_def_data_len)
        
        website_knowledge_kg_data = [[k.lower(), g[0], g[1].lower()] for k,v in website_knowledge_dict.items() for g in v['relations']]   # a, ->, b
        website_knowledge_kg_data_len = len(website_knowledge_kg_data)
        num_website_knowledge_kg_pool = round(sample_website_knowledge_kg_ratio * website_knowledge_kg_data_len)

        # Load definition from GPT-genrated label-definitions
        with open(supplementary_file, 'r') as json_file:
            supplementary_dict = json.load(json_file)
            
        supplementary_def_data = [[k.lower(), v['cleaned_definition']] for k,v in supplementary_dict.items() if 'cleaned_definition' in v] # lab, def
        # First filter items that have 'synonyms' key, then iterate through the synonyms
        supplementary_def_data += [[k.lower(), synonym] for k,v in supplementary_dict.items() if 'synonyms' in v for synonym in v['synonyms']]  # lab, synonym
        supplementary_def_data_len = len(supplementary_def_data)
        num_supplementary_def_pool = round(sample_supplementary_def_ratio * supplementary_def_data_len)
        
        supplementary_kg_data = [[k.lower(), g[0], g[1].lower()] for k,v in supplementary_dict.items() for g in v['relations']]   # a, ->, b
        supplementary_kg_data_len = len(supplementary_kg_data)
        num_supplementary_kg_pool = round(sample_supplementary_kg_ratio * supplementary_kg_data_len)
        
        self.data = [[umls_def_data, 'umls_def'], [umls_kg_data, 'umls_kg'], [website_knowledge_def_data, 'website_knowledge_def'], [website_knowledge_kg_data, 'website_knowledge_kg'], [supplementary_def_data, 'supplementary_def'], [supplementary_kg_data, 'supplementary_kg']]
        self.weight = [num_umls_def_pool, num_umls_kg_pool, num_website_knowledge_def_pool, num_website_knowledge_kg_pool, num_supplementary_def_pool, num_supplementary_kg_pool]
        pool_size = sum(self.weight)
        self.weight = [w/pool_size for w in self.weight]
        
        if "RANK" not in os.environ or int(os.environ["RANK"]) == 0:
            print(f'** DATASET ** UMLS DEF data length: {umls_def_data_len}, {num_umls_def_pool} in an pool')
            print(f'** DATASET ** UMLS KG data length: {umls_kg_data_len}, {num_umls_kg_pool} in an pool')
            print(f'** DATASET ** Website Knowledge DEF data length: {website_knowledge_def_data_len}, {num_website_knowledge_def_pool} in an pool')
            print(f'** DATASET ** Website Knowledge KG data length: {website_knowledge_kg_data_len}, {num_website_knowledge_kg_pool} in an pool')
            print(f'** DATASET ** Supplementary DEF data length: {supplementary_def_data_len}, {num_supplementary_def_pool} in an pool')
            print(f'** DATASET ** Supplementary KG data length: {supplementary_kg_data_len}, {num_supplementary_kg_pool} in an pool')
            print(f'** DATASET ** Sampling Weight for them: {self.weight}')
            print('\n')
        
    def __len__(self):
        return 100000000
    
    def _get_single_item(self):
        data_ls, name = random.choices(self.data, weights=self.weight, k=1)[0]
        text_ls = random.choice(data_ls)

        if len(text_ls) == 3:   # triple relation
            source, edge, target = text_ls
            source = source
            target = target
            if isinstance(target, list):
                target = random.choice(target)  # list of equivalent expressions
            if random.random()<0.5:
                pos_text = source + ' ' + edge    # A ->
                label_text =  target  # B
            else:
                pos_text = edge + ' ' + target    # -> B
                label_text =  source  # A
        elif len(text_ls) == 2: # definition
            label, defi = text_ls
            label = label
            label_text = label
            pos_text = defi

        return label_text, pos_text

    def __getitem__(self, idx):
        pos_text_ls = []
        label_text_ls = []
        
        data_ls, name = random.choices(self.data, weights=self.weight, k=1)[0]
        text_ls = random.choice(data_ls)

        # triple relation
        if len(text_ls) == 3:
            source, edge, target = text_ls
            source = source
            target = target
            if isinstance(target, list):
                target = random.choice(target)  # list of equivalent expressions
            if random.random()<0.5:
                pos_text_ls.append(source + ' ' + edge)    # A ->
                label_text_ls.append(target)  # B
            else:
                pos_text_ls.append(edge + ' ' + target)    # -> B
                label_text_ls.append(source)  # A
        
        # definition            
        elif len(text_ls) == 2: 
            label, defi = text_ls
            label = label
            label_text_ls.append(label)
            pos_text_ls.append(defi)
            
        sample = {}
        sample['label_text'] = label_text_ls
        sample['pos_text'] = pos_text_ls
        return sample


class Med_SAM_Dataset(Dataset):
    def __init__(self, 
                 jsonl_file,
                 crop_size=[288,288,96],
                 # uncenter_prob=0.5,
                 ):
        """
        Assemble 46 segmentation datasets
        
        Args:
            json_file (_type_): a jsonl contains all train sample information.
            crop_size (int, optional): Defaults to [288,288,96].
            uncenter_prob (float, optional): Prob to shift the crop in roi. Defaults to 0.5.
        """
        # data processing
        self.crop_size = crop_size
        
        # self.uncenter_prob = 0 if eval_mode else uncenter_prob 
        
        # load data info        
        self.jsonl_file = jsonl_file
        with open(self.jsonl_file, 'r') as f:
            lines = f.readlines()
        lines = [json.loads(line) for line in lines]
        
        # statistics the size of each dataset
        datasets_dist = [l['dataset'] for l in lines]
        self.datasets_size = {}
        for dataset in datasets_dist:
            if dataset in self.datasets_size:
                continue
            else:
                self.datasets_size[dataset] = datasets_dist.count(dataset)
        
        anno_num = 0
        self.data = {}  # 'liver': {'data_list':[datum_in_jsonl, ...], 'sample_weight':[0.1, ...]}
        self.datasets = set()
        self.labels = set()
        self.label_in_pool = []

        for sample in lines:
                 
            # sampling weight for samples in this dataset
            self.datasets.add(sample['dataset'])
            # inverse to square root of dataset size
            size = self.datasets_size[sample['dataset']]
            weight = 1 / (math.sqrt(size))
            
            # add      
            for label, not_empty in zip(sample['label'], sample['renorm_y1x1z1_y2x2z2']):
                if not_empty:
                    if label not in self.data:
                        self.data[label] = {'data_list':[], 'sample_weight':[]}
                        self.labels.add(label)
                    
                    self.data[label]['data_list'].append(sample)
                    self.data[label]['sample_weight'].append(weight)
                    anno_num += 1
                    
        # repeat : labels with N occurance should be repeated sqrt(N)
        for label in self.labels:
            num = len(self.data[label]['data_list']) 
            num = round(math.sqrt(num))
            self.label_in_pool += [label] * num
        
        if "RANK" not in os.environ or int(os.environ["RANK"]) == 0:
            print(f'** DATASET ** In total {len(self.datasets)} datasets. ')
            print(f'** DATASET ** In total {len(self.data.keys())} labels. ')
            print(f'** DATASET ** In total {anno_num} annotations. ')
            # print(f'** DATASET ** Local : {local_num}, Non-Local : {nonlocal_num} ')
            print(f'** DATASET ** Size for each dataset : {self.datasets_size}')
            print(f'** DATASET ** Sample {len(self.label_in_pool)} in an epoch. ')
            print('\n')
             
    def __len__(self):
        return 1000000000
    
    def _merge_modality(self, mod):
        if contains(mod, ['t1', 't2', 'mri', 'flair', 'dwi']):
            return 'mri'
        if contains(mod, 'ct'):
            return 'ct'
        if contains(mod, 'pet'):
            return 'pet'
        if contains(mod, ['us', 'ultrasound']):
            return 'us'
        else:
            return mod
    
    def _pad_if_necessary(self, image=None, mask=None):
        # image size >= crop size 
        if not (image is None):
            c, h, w, d = image.shape
            croph, cropw, cropd = self.crop_size
            pad_in_h = 0 if h >= croph else croph - h
            pad_in_w = 0 if w >= cropw else cropw - w
            pad_in_d = 0 if d >= cropd else cropd - d
            if pad_in_h + pad_in_w + pad_in_d > 0:
                pad = (0, pad_in_d, 0, pad_in_w, 0, pad_in_h)
                image = F.pad(image, pad, 'constant', 0)   # chwd
        
        if not (mask is None):
            n, h, w, d = mask.shape
            croph, cropw, cropd = self.crop_size
            pad_in_h = 0 if h >= croph else croph - h
            pad_in_w = 0 if w >= cropw else cropw - w
            pad_in_d = 0 if d >= cropd else cropd - d
            if pad_in_h + pad_in_w + pad_in_d > 0:
                pad = (0, pad_in_d, 0, pad_in_w, 0, pad_in_h)
                mask = F.pad(mask, pad, 'constant', 0)   # nhwd
        
        return image, mask
    
    def _roi_crop(self, image, mask):
        # c h w d & n h w d
        _, imgh, imgw, imgd = image.shape
        croph, cropw, cropd = self.crop_size
        
        mask_to_select = mask
        
        # select a voxel
        voxels_foreground = torch.nonzero(mask_to_select, as_tuple=True)   # (tensor(...), tensor(...), tensor(...))
        selected_index = random.randint(0, voxels_foreground[0].shape[0]-1)
        selected_voxel = (voxels_foreground[0][selected_index].item(), voxels_foreground[1][selected_index].item(), voxels_foreground[2][selected_index].item())
        
        # check the boundary
        if selected_voxel[0] - croph // 2 > 0:
            start_y = selected_voxel[0] - croph // 2
            if start_y + croph < imgh:
                end_y = start_y + croph
            else:
                end_y = imgh
                start_y = imgh-croph
        else:
            start_y = 0
            end_y = croph
            
        if selected_voxel[1] - cropw // 2 > 0:
            start_x = selected_voxel[1] - cropw // 2
            if start_x + cropw < imgw:
                end_x = start_x + cropw
            else:
                end_x = imgw
                start_x = imgw-cropw
        else:
            start_x = 0
            end_x = cropw

        if selected_voxel[2] - cropd // 2 > 0:
            start_z = selected_voxel[2] - cropd // 2
            if start_z + cropd < imgd:
                end_z = start_z + cropd
            else:
                end_z = imgd
                start_z = imgd-cropd
        else:
            start_z = 0
            end_z = cropd  
            
        # if random.random() < self.uncenter_prob:
        #     # randomly shift the crop (must contain the selected voxel
        #     y_left_space = min(start_y - 0, end_y - selected_voxel[0])
        #     y_right_space = min(imgh - end_y, selected_voxel[0] - start_y)
        #     y_adjust = random.randint(-1 * y_left_space, y_right_space)
        #     start_y += y_adjust
        #     end_y += y_adjust
            
        #     x_left_space  = min(start_x-0, end_x-selected_voxel[1])
        #     x_right_space = min(imgw-end_x, selected_voxel[1]-start_x)
        #     x_adjust = random.randint(-1*x_left_space, x_right_space)
        #     start_x += x_adjust
        #     end_x += x_adjust

        #     z_left_space = min(start_z - 0, end_z - selected_voxel[2])
        #     z_right_space = min(imgd - end_z, selected_voxel[2] - start_z)
        #     z_adjust = random.randint(-1 * z_left_space, z_right_space)
        #     start_z += z_adjust
        #     end_z += z_adjust
        
        # crop
        crop_image = image[:, start_y:end_y, start_x:end_x, start_z:end_z]
        crop_mask = mask[:, start_y:end_y, start_x:end_x, start_z:end_z]

        return crop_image, crop_mask, [start_y, start_x, start_z, end_y, end_x, end_z]
    
    def _load_mask(self, datum, labels_to_load):
        """
        加载segmentation mask
        Args:
            datum (dict): sample info (a line from jsonl file

        Returns:
            mc_mask: (N, h, w, d)
        """
        _, h, w, d = datum['chwd']
        
        mc_mask = []
        is_pos = []
        for label in labels_to_load:
            mask_path= f"{datum['renorm_segmentation_dir']}/{label}.npy"
            index = datum['label'].index(label)
            y1x1z1_y2x2z2 = datum['renorm_y1x1z1_y2x2z2'][index]
            
            mask = torch.zeros((h, w, d), dtype=torch.bool)
            # not empty, load and embed non-empty cropped_volume
            if y1x1z1_y2x2z2 != False:
                y1, x1, z1, y2, x2, z2 = y1x1z1_y2x2z2
                mask[y1:y2, x1:x2, z1:z2] = torch.tensor(np.load(mask_path))
                is_pos.append(True)
            else:
                is_pos.append(False)
            mc_mask.append(mask)
            
        mc_mask = torch.stack(mc_mask, dim=0)   # n h w d
        
        return mc_mask
    
    def _load_image(self, datum):
        # if the local copy exists
        # NOTE: Make sure the local copy consistent
        path = datum['renorm_image']
        # local_path_202 = path.replace('/remote-home/share/SAM', '/remote-home/share/data202/172.16.11.202/SAM')
        # if os.path.exists(local_path_202):
        #     path = local_path_202
        image = torch.tensor(np.load(path))

        return image # chwd
    
    def is_overlap(self, a_y1x1z1_y2x2z2, b_y1x1z1_y2x2z2):
        # judge is overlap or not between two cubes
        a_y1, a_x1, a_z1, a_y2, a_x2, a_z2 = a_y1x1z1_y2x2z2
        b_y1, b_x1, b_z1, b_y2, b_x2, b_z2 = b_y1x1z1_y2x2z2
        overlap_x = not (a_x2 < b_x1 or b_x2 < a_x1)
        overlap_y = not (a_y2 < b_y1 or b_y2 < a_y1)
        overlap_z = not (a_z2 < b_z1 or b_z2 < a_z1)
        return overlap_x and overlap_y and overlap_z
    
    def _find_pos_labels_in_crop(self, crop_y1x1z1_y2x2z2, labels_y1x1z1_y2x2z2):
        is_pos = []
        for y1x1z1_y2x2z2 in labels_y1x1z1_y2x2z2:
            if y1x1z1_y2x2z2 and self.is_overlap(y1x1z1_y2x2z2, crop_y1x1z1_y2x2z2):
                is_pos.append(True)
            else:
                is_pos.append(False)
        return is_pos
        
    def __getitem__(self, idx):
        while True:
            try:
                # choose image scan
                label = random.choice(self.label_in_pool)
                sample = random.choices(self.data[label]['data_list'], self.data[label]['sample_weight'], k=1)[0]
                label = [label]
                
                # load image
                image = self._load_image(sample)

                # load masks based on chosen label
                mask = self._load_mask(sample, label)    # 1, h, w, d

                # merge modality, e.g. t1 -> mri
                modality = sample['modality']
                modality = self._merge_modality(modality.lower())
                modality_code = {
                    'ct':0,
                    'mri':1,
                    'us':2,
                    'pet':3,
                }[modality]

                # Pad image and mask
                image, mask = self._pad_if_necessary(image, mask)

                # Crop image and mask
                image, mask, y1x1z1_y2x2z2 = self._roi_crop(image, mask)    # chwd, 1hwd

                # Find other positive labels
                is_pos_in_crop = self._find_pos_labels_in_crop(y1x1z1_y2x2z2, sample['renorm_y1x1z1_y2x2z2'])   # [label1, label2, ....] --> [True, False, ...]
                candidates = []
                for label_name, is_pos in zip(sample['label'], is_pos_in_crop):
                    if is_pos and label_name != label[0]:
                        candidates.append(label_name)
                        
                # choose up to 9 other labels      
                if len(candidates) > 0:
                    other_labels = random.choices(candidates, k=min(len(candidates), 7))
                    other_mask = self._load_mask(sample, other_labels)
                    # pad and crop
                    _, other_mask = self._pad_if_necessary(image=None, mask=other_mask)
                    y1, x1, z1, y2, x2, z2 = y1x1z1_y2x2z2
                    other_mask = other_mask[:, y1:y2, x1:x2, z1:z2]
                    # add
                    label += other_labels
                    mask = torch.concat([mask, other_mask], dim=0)  # nhwd
                
                _, H, W, D = image.shape
                _, mH, mW, mD = mask.shape
                assert H == mH and W == mW and D == mD, f'image shape {H, W, D} inconsistent with mask shape {mH, mW, mD}'
                        
                """# augmentation if needed
                if sample['dataset'] in self.augmentator:
                    data_dict = {'image': image, 'label': mask}
                    aug_data_dict = self.augmentator[sample['dataset']](data_dict)
                    image, mask = aug_data_dict['image'], aug_data_dict['label']"""

                return {'image':image, 'mask':mask, 'label_name':label, 'modality':modality_code, 'image_path':sample['renorm_image'], 'mask_path':sample['renorm_segmentation_dir'], 'y1x1z1_y2x2z2':y1x1z1_y2x2z2}
            
            except SystemExit:
                exit()
            except:
                traceback.print_exc()
                print(f'*** {sample["dataset"]} *** {sample["image"]} ***\n')
     
     
class Med_SAM_Dataset_npz(Dataset):
    def __init__(self, 
                 jsonl_file,
                 crop_size=[288,288,96],
                 # uncenter_prob=0.5,
                 ):
        """
        Assemble 46 segmentation datasets
        
        Args:
            json_file (_type_): a jsonl contains all train sample information.
            crop_size (int, optional): Defaults to [288,288,96].
            uncenter_prob (float, optional): Prob to shift the crop in roi. Defaults to 0.5.
        """
        # data processing
        self.crop_size = crop_size
        
        # self.uncenter_prob = 0 if eval_mode else uncenter_prob 
        
        # load data info        
        self.jsonl_file = jsonl_file
        with open(self.jsonl_file, 'r') as f:
            lines = f.readlines()
        lines = [json.loads(line) for line in lines]
        
        # load intensity 2 label json
        with open('/mnt/petrelfs/zhaoziheng/Knowledge-Enhanced-Medical-Segmentation/SegFM3D/CVPR25_TextSegFMData_with_class.json', 'r') as f:
            self.label_json = json.load(f)
        
        # statistics the size of each dataset
        datasets_dist = [l['dataset'] for l in lines]
        self.datasets_size = {}
        for dataset in datasets_dist:
            if dataset in self.datasets_size:
                continue
            else:
                self.datasets_size[dataset] = datasets_dist.count(dataset)
        
        anno_num = 0
        self.data = {}  # 'liver': {'data_list':[datum_in_jsonl, ...], 'sample_weight':[0.1, ...]}
        self.datasets = set()
        self.labels = set()
        self.label_in_pool = []

        for sample in lines:
                 
            # sampling weight for samples in this dataset
            self.datasets.add(sample['dataset'])
            # inverse to square root of dataset size
            size = self.datasets_size[sample['dataset']]
            weight = 1 / (math.sqrt(size))
            
            # add by label   
            label_ls = self.label_json[sample['dataset']]  # "1":['xxx', 'xxx', ...]
            label_ls = [tuple(ls) for ls in label_ls.values() if isinstance(ls, list)]  # ('xxx', 'xxx', ...)
            for label, not_empty in zip(label_ls, sample['label_existance']):
                if not_empty:
                    if label not in self.data:
                        self.data[label] = {'data_list':[], 'sample_weight':[]}
                        self.labels.add(label)
                    
                    self.data[label]['data_list'].append(sample)
                    self.data[label]['sample_weight'].append(weight)
                    anno_num += 1
                    
        # repeat : labels with N occurance should be repeated sqrt(N)
        for label in self.labels:
            num = len(self.data[label]['data_list']) 
            num = round(math.sqrt(num))
            self.label_in_pool += [label] * num
        
        if "RANK" not in os.environ or int(os.environ["RANK"]) == 0:
            print(f'** DATASET ** In total {len(self.datasets)} datasets. ')
            print(f'** DATASET ** In total {len(self.data.keys())} labels. ')
            print(f'** DATASET ** In total {anno_num} annotations. ')
            # print(f'** DATASET ** Local : {local_num}, Non-Local : {nonlocal_num} ')
            print(f'** DATASET ** Size for each dataset : {self.datasets_size}')
            print(f'** DATASET ** Sample {len(self.label_in_pool)} in an epoch. ')
            print('\n')
             
    def __len__(self):
        return 1000000000
    
    def _merge_modality(self, mod):
        if contains(mod, ['mr', 't1', 't2', 'mri', 'flair', 'dwi']):
            return 'mri'
        if contains(mod, 'ct'):
            return 'ct'
        if contains(mod, 'pet'):
            return 'pet'
        if contains(mod, ['us', 'us3d', 'ultrasound']):
            return 'us'
        if contains(mod, ['microscopy']):
            return 'microscopy'
        else:
            return mod
    
    def _pad_if_necessary(self, image=None, mask=None):
        # image size >= crop size 
        if not (image is None):
            c, h, w, d = image.shape
            croph, cropw, cropd = self.crop_size
            pad_in_h = 0 if h >= croph else croph - h
            pad_in_w = 0 if w >= cropw else cropw - w
            pad_in_d = 0 if d >= cropd else cropd - d
            if pad_in_h + pad_in_w + pad_in_d > 0:
                pad = (0, pad_in_d, 0, pad_in_w, 0, pad_in_h)
                image = F.pad(image, pad, 'constant', 0)   # chwd
        
        if not (mask is None):
            n, h, w, d = mask.shape
            croph, cropw, cropd = self.crop_size
            pad_in_h = 0 if h >= croph else croph - h
            pad_in_w = 0 if w >= cropw else cropw - w
            pad_in_d = 0 if d >= cropd else cropd - d
            if pad_in_h + pad_in_w + pad_in_d > 0:
                pad = (0, pad_in_d, 0, pad_in_w, 0, pad_in_h)
                mask = F.pad(mask, pad, 'constant', 0)   # nhwd
        
        return image, mask
    
    def _roi_crop(self, image, mask):
        # c h w d & n h w d
        _, imgh, imgw, imgd = image.shape
        croph, cropw, cropd = self.crop_size
        
        mask_to_select = mask
        
        # select a voxel
        voxels_foreground = torch.nonzero(mask_to_select, as_tuple=True)   # (tensor(...), tensor(...), tensor(...))
        selected_index = random.randint(0, voxels_foreground[0].shape[0]-1)
        selected_voxel = (voxels_foreground[0][selected_index].item(), voxels_foreground[1][selected_index].item(), voxels_foreground[2][selected_index].item())
        
        # check the boundary
        if selected_voxel[0] - croph // 2 > 0:
            start_y = selected_voxel[0] - croph // 2
            if start_y + croph < imgh:
                end_y = start_y + croph
            else:
                end_y = imgh
                start_y = imgh-croph
        else:
            start_y = 0
            end_y = croph
            
        if selected_voxel[1] - cropw // 2 > 0:
            start_x = selected_voxel[1] - cropw // 2
            if start_x + cropw < imgw:
                end_x = start_x + cropw
            else:
                end_x = imgw
                start_x = imgw-cropw
        else:
            start_x = 0
            end_x = cropw

        if selected_voxel[2] - cropd // 2 > 0:
            start_z = selected_voxel[2] - cropd // 2
            if start_z + cropd < imgd:
                end_z = start_z + cropd
            else:
                end_z = imgd
                start_z = imgd-cropd
        else:
            start_z = 0
            end_z = cropd  
            
        # if random.random() < self.uncenter_prob:
        #     # randomly shift the crop (must contain the selected voxel
        #     y_left_space = min(start_y - 0, end_y - selected_voxel[0])
        #     y_right_space = min(imgh - end_y, selected_voxel[0] - start_y)
        #     y_adjust = random.randint(-1 * y_left_space, y_right_space)
        #     start_y += y_adjust
        #     end_y += y_adjust
            
        #     x_left_space  = min(start_x-0, end_x-selected_voxel[1])
        #     x_right_space = min(imgw-end_x, selected_voxel[1]-start_x)
        #     x_adjust = random.randint(-1*x_left_space, x_right_space)
        #     start_x += x_adjust
        #     end_x += x_adjust

        #     z_left_space = min(start_z - 0, end_z - selected_voxel[2])
        #     z_right_space = min(imgd - end_z, selected_voxel[2] - start_z)
        #     z_adjust = random.randint(-1 * z_left_space, z_right_space)
        #     start_z += z_adjust
        #     end_z += z_adjust
        
        # crop
        crop_image = image[:, start_y:end_y, start_x:end_x, start_z:end_z]
        crop_mask = mask[:, start_y:end_y, start_x:end_x, start_z:end_z]

        return crop_image, crop_mask, [start_y, start_x, start_z, end_y, end_x, end_z]
    
    def sc_mask_to_mc_mask(self, sc_mask, label_values_ls):
        assert sc_mask.ndim == 3
        h, w, d = sc_mask.shape
        n = len(label_values_ls)
        mc_mask = np.zeros((n, h, w, d), dtype=bool)
        for i, label_value in enumerate(label_values_ls):
            mc_mask[i] = np.where(sc_mask == label_value, 1, 0)
        return mc_mask
    
    def load_npz_data(self, dataset_name, data_path):
        data = np.load(data_path)
        sample_name = os.path.basename(data_path)[:-4]
        
        img = data['imgs'].astype(np.float32)  # 0~255
        sc_mask = data['gts'].astype(np.float32)
        spacing = data['spacing'].tolist()
        
        img, sc_mask, spacing = NAME2LOADER[dataset_name](sample_name, img, sc_mask, spacing)
        img = img[np.newaxis, :, :, :]  # 1 h w d
        
        label_2_text_prompt = self.label_json[dataset_name] # '1':['xxx', 'xxx', ...]
        label_values_ls = list(label_2_text_prompt.keys())
        label_values_ls = [int(v) for v in label_values_ls if v!='instance_label']
        text_prompt_ls = list(label_2_text_prompt.values()) # list of list of str
        text_prompt_ls = [ls for ls in text_prompt_ls if isinstance(ls, list)]
        
        mc_mask = self.sc_mask_to_mc_mask(sc_mask, label_values_ls)  # n h w d
        
        return torch.from_numpy(img.copy()), torch.from_numpy(mc_mask.copy()), text_prompt_ls
    
    def is_overlap(self, a_y1x1z1_y2x2z2, b_y1x1z1_y2x2z2):
        # judge is overlap or not between two cubes
        a_y1, a_x1, a_z1, a_y2, a_x2, a_z2 = a_y1x1z1_y2x2z2
        b_y1, b_x1, b_z1, b_y2, b_x2, b_z2 = b_y1x1z1_y2x2z2
        overlap_x = not (a_x2 < b_x1 or b_x2 < a_x1)
        overlap_y = not (a_y2 < b_y1 or b_y2 < a_y1)
        overlap_z = not (a_z2 < b_z1 or b_z2 < a_z1)
        return overlap_x and overlap_y and overlap_z
    
    def _find_pos_labels_in_crop(self, crop_y1x1z1_y2x2z2, labels_y1x1z1_y2x2z2):
        is_pos = []
        for y1x1z1_y2x2z2 in labels_y1x1z1_y2x2z2:
            if y1x1z1_y2x2z2 and self.is_overlap(y1x1z1_y2x2z2, crop_y1x1z1_y2x2z2):
                is_pos.append(True)
            else:
                is_pos.append(False)
        return is_pos
        
    def __getitem__(self, idx):
        while True:
            try:
                # choose image scan
                chosen_label = random.choice(self.label_in_pool)    # ('xxx', 'xxx', ...)
                datum = random.choices(self.data[chosen_label]['data_list'], self.data[chosen_label]['sample_weight'], k=1)[0]
                data_path = datum['data']
                dataset = datum['dataset']
                
                # load image and all masks
                image, mc_mask, labels = self.load_npz_data(dataset, data_path)   # 1HWD NHWD
                labels = [tuple(ls) for ls in labels]

                # merge modality, e.g. t1 -> mri
                modality = data_path.split('/')[-3]
                modality = self._merge_modality(modality.lower())
                modality_code = {
                    'ct':0,
                    'mri':1,
                    'us':2,
                    'pet':3,
                    'microscopy':4,
                }[modality]

                # Pad image and mask
                image, mc_mask = self._pad_if_necessary(image, mc_mask)

                # Crop image and mask (based on the chosen label)
                channel_idx = labels.index(chosen_label)
                chosen_mask = mc_mask[channel_idx:channel_idx+1]  # 1HWD
                image, _, y1x1z1_y2x2z2 = self._roi_crop(image, chosen_mask)    # 1hwd, 1hwd
                mc_mask = mc_mask[:, y1x1z1_y2x2z2[0]:y1x1z1_y2x2z2[3], y1x1z1_y2x2z2[1]:y1x1z1_y2x2z2[4], y1x1z1_y2x2z2[2]:y1x1z1_y2x2z2[5]]

                # Find other positive labels
                candidates = []
                for idx, label in enumerate(labels):
                    if label[0] != chosen_label[0] and torch.any(mc_mask[idx]):
                        candidates.append((idx, label))
                        
                # choose up to 3 other labels      
                if len(candidates) > 0:
                    other_labels = random.choices(candidates, k=min(len(candidates), 3))
                    final_labels = [chosen_label] + [tmp[1] for tmp in other_labels]    # [('xxx', ...), ...]
                    all_idx = [channel_idx] + [tmp[0] for tmp in other_labels]
                else:
                    final_labels = [chosen_label]
                    all_idx = [channel_idx]
                all_idx = torch.tensor(all_idx)
                final_mask = torch.index_select(mc_mask, dim=0, index=all_idx)
                    
                # each label chose one expression as text prompt
                id_list = [labels[0] for labels in final_labels]
                final_labels = [random.choice(labels) for labels in final_labels]
                
                _, H, W, D = image.shape
                _, mH, mW, mD = final_mask.shape
                assert H == mH and W == mW and D == mD, f'image shape {H, W, D} inconsistent with mask shape {mH, mW, mD}'
                        
                """# augmentation if needed
                if sample['dataset'] in self.augmentator:
                    data_dict = {'image': image, 'label': mask}
                    aug_data_dict = self.augmentator[sample['dataset']](data_dict)
                    image, mask = aug_data_dict['image'], aug_data_dict['label']"""

                return {'image':image, 'mask':final_mask, 'label_name':final_labels, 'id_ls':id_list, 'modality':modality_code, 'image_path':data_path, 'mask_path':data_path, 'y1x1z1_y2x2z2':y1x1z1_y2x2z2}
            
            except SystemExit:
                exit()
            except:
                traceback.print_exc()
                print(f'*** {data_path} *** \n')